{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 49,F,NAP,160,180,0,Normal,156,N,1,Flat,1\n",
    "\n",
    "data = {\n",
    "            \"Age\": 40,\n",
    "            \"Sex\": \"F\",\n",
    "            \"ChestPainType\": \"NAP\",\n",
    "            \"RestingBP\": 160,\n",
    "            \"Cholesterol\": 180,\n",
    "            \"FastingBS\": 0,\n",
    "            \"RestingECG\": \"Normal\",\n",
    "            \"MaxHR\": 156,\n",
    "            \"ExerciseAngina\": \"n\",\n",
    "            \"Oldpeak\": 1,\n",
    "            \"ST_Slope\": \"Flat\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(data):\n",
    "    # Create an Example proto from your feature dict.\n",
    "    feature_spec = {\n",
    "        \"Age\": tf.train.Feature(int64_list=tf.train.Int64List(value=[data['Age']])),\n",
    "        \"Sex\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[bytes(data['Sex'], \"utf-8\")])),\n",
    "        \"ChestPainType\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[bytes(data['ChestPainType'], \"utf-8\")])),\n",
    "        \"RestingBP\": tf.train.Feature(int64_list=tf.train.Int64List(value=[data['RestingBP']])),\n",
    "        \"Cholesterol\": tf.train.Feature(int64_list=tf.train.Int64List(value=[data['Cholesterol']])),\n",
    "        \"FastingBS\": tf.train.Feature(int64_list=tf.train.Int64List(value=[data['FastingBS']])),\n",
    "        \"RestingECG\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[bytes(data['RestingECG'], \"utf-8\")])),\n",
    "        \"MaxHR\": tf.train.Feature(int64_list=tf.train.Int64List(value=[data['MaxHR']])),\n",
    "        \"ExerciseAngina\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[bytes(data['ExerciseAngina'], \"utf-8\")])),\n",
    "        \"Oldpeak\": tf.train.Feature(float_list=tf.train.FloatList(value=[data['Oldpeak']])),\n",
    "        \"ST_Slope\": tf.train.Feature(bytes_list=tf.train.BytesList(value=[bytes(data['ST_Slope'], \"utf-8\")]))\n",
    "    }\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_spec)).SerializeToString()\n",
    "    result = [{'examples': {'b64': base64.b64encode(example).decode('utf-8')}}]\n",
    "    \n",
    "    return json.dumps(\n",
    "        {\n",
    "            \"signature_name\":\"serving_default\",\n",
    "            \"instances\": result\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"instances\": [{\"b64\": \"CuUBCgwKA0FnZRIFGgMKASgKDwoFTWF4SFISBhoECgKcAQoTCglSZXN0aW5nQlASBhoECgKgAQoYCgpSZXN0aW5nRUNHEgoKCAoGTm9ybWFsChMKB09sZHBlYWsSCBIGCgQAAIA/CgwKA1NleBIFCgMKAUYKEgoJRmFzdGluZ0JTEgUaAwoBAAoUCghTVF9TbG9wZRIICgYKBEZsYXQKFQoLQ2hvbGVzdGVyb2wSBhoECgK0AQoYCg1DaGVzdFBhaW5UeXBlEgcKBQoDTkFQChcKDkV4ZXJjaXNlQW5naW5hEgUKAwoBbg==\"}]}\n"
     ]
    }
   ],
   "source": [
    "print(prepare(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'JSON Value: \"{\\\\\"signature_name\\\\\": \\\\\"serving_default\\\\\", \\\\\"instances\\\\\": [{\\\\\"examples\\\\\": {\\\\\"b64\\\\\": \\\\\"CuUBChIKCUZhc3RpbmdCUxIFGgMKAQAKFAoIU1RfU2xvcGUSCAoGCgRGbGF0ChgKDUNoZXN0UGFpblR5cGUSBwoFCgNOQVAKFQoLQ2hvbGVzdGVyb2wSBhoECgK0AQoPCgVNYXhIUhIGGgQKApwBChcKDkV4ZXJjaXNlQW5naW5hEgUKAwoBbgoTCglSZXN0aW5nQlASBhoECgKgAQoTCgdPbGRwZWFrEggSBgoEAACAPwoMCgNBZ2USBRoDCgEoChgKClJlc3RpbmdFQ0cSCgoICgZOb3JtYWwKDAoDU2V4EgUKAwoBRg==\\\\\"}}]}\" Is not object'}\n"
     ]
    }
   ],
   "source": [
    "endpoint = \"https://mlops-tfx-production-1022.up.railway.app/v1/models/cc-model:predict\"\n",
    " \n",
    "response = requests.post(endpoint, json=prepare(data))\n",
    " \n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
